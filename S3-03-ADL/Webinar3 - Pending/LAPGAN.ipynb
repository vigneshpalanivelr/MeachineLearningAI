{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG3-Cy-9lmpw"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# @Author: aaronlai\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "class CondiGAN_Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, n_layer=3, condition=True, n_condition=100,\n",
        "                 use_gpu=False, featmap_dim=256, n_channel=1,\n",
        "                 condi_featmap_dim=256):\n",
        "        \"\"\"\n",
        "        Conditional Discriminator.\n",
        "        Architecture brought from DCGAN.\n",
        "        \"\"\"\n",
        "        super(CondiGAN_Discriminator, self).__init__()\n",
        "        self.n_layer = n_layer\n",
        "        self.condition = condition\n",
        "\n",
        "        # original Discriminator\n",
        "        self.featmap_dim = featmap_dim\n",
        "\n",
        "        convs = []\n",
        "        BNs = []\n",
        "        for layer in range(self.n_layer):\n",
        "            if layer == (self.n_layer - 1):\n",
        "                n_conv_in = n_channel\n",
        "            else:\n",
        "                n_conv_in = int(featmap_dim / (2**(layer + 1)))\n",
        "            n_conv_out = int(featmap_dim / (2**layer))\n",
        "\n",
        "            _conv = nn.Conv2d(n_conv_in, n_conv_out, kernel_size=5,\n",
        "                              stride=2, padding=2)\n",
        "            if use_gpu:\n",
        "                _conv = _conv.cuda()\n",
        "            convs.append(_conv)\n",
        "\n",
        "            if layer != (self.n_layer - 1):\n",
        "                _BN = nn.BatchNorm2d(n_conv_out)\n",
        "                if use_gpu:\n",
        "                    _BN = _BN.cuda()\n",
        "                BNs.append(_BN)\n",
        "\n",
        "        # extra image information to be conditioned on\n",
        "        if self.condition:\n",
        "            self.condi_featmap_dim = condi_featmap_dim\n",
        "            convs_condi = []\n",
        "            BNs_condi = []\n",
        "\n",
        "            for layer in range(self.n_layer):\n",
        "                if layer == (self.n_layer - 1):\n",
        "                    n_conv_in = n_channel\n",
        "                else:\n",
        "                    n_conv_in = int(condi_featmap_dim / (2**(layer + 1)))\n",
        "                n_conv_out = int(condi_featmap_dim / (2**layer))\n",
        "\n",
        "                _conv = nn.Conv2d(n_conv_in, n_conv_out, kernel_size=5,\n",
        "                                  stride=2, padding=2)\n",
        "                if use_gpu:\n",
        "                    _conv = _conv.cuda()\n",
        "                convs_condi.append(_conv)\n",
        "\n",
        "                if layer != (self.n_layer - 1):\n",
        "                    _BN = nn.BatchNorm2d(n_conv_out)\n",
        "                    if use_gpu:\n",
        "                        _BN = _BN.cuda()\n",
        "                    BNs_condi.append(_BN)\n",
        "\n",
        "            self.fc_c = nn.Linear(condi_featmap_dim * 4 * 4, n_condition)\n",
        "\n",
        "        # register layer modules\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.BNs = nn.ModuleList(BNs)\n",
        "        if self.condition:\n",
        "            self.convs_condi = nn.ModuleList(convs_condi)\n",
        "            self.BNs_condi = nn.ModuleList(BNs_condi)\n",
        "\n",
        "        # output layer\n",
        "        n_hidden = featmap_dim * 4 * 4\n",
        "        if self.condition:\n",
        "            n_hidden += n_condition\n",
        "        self.fc = nn.Linear(n_hidden, 1)\n",
        "\n",
        "    def forward(self, x, condi_x=None):\n",
        "        \"\"\"\n",
        "        Concatenate CNN-processed extra information vector at the last layer\n",
        "        \"\"\"\n",
        "        for layer in range(self.n_layer):\n",
        "            conv_layer = self.convs[self.n_layer - layer - 1]\n",
        "            if layer == 0:\n",
        "                x = F.leaky_relu(conv_layer(x), negative_slope=0.2)\n",
        "            else:\n",
        "                BN_layer = self.BNs[self.n_layer - layer - 1]\n",
        "                x = F.leaky_relu(BN_layer(conv_layer(x)), negative_slope=0.2)\n",
        "        x = x.view(-1, self.featmap_dim * 4 * 4)\n",
        "\n",
        "        # calculate and concatenate extra information\n",
        "        if self.condition:\n",
        "            for layer in range(self.n_layer):\n",
        "                _conv = self.convs_condi[self.n_layer - layer - 1]\n",
        "                if layer == 0:\n",
        "                    condi_x = F.leaky_relu(_conv(condi_x), negative_slope=0.2)\n",
        "                else:\n",
        "                    BN_layer = self.BNs_condi[self.n_layer - layer - 1]\n",
        "                    condi_x = F.leaky_relu(BN_layer(_conv(condi_x)),\n",
        "                                           negative_slope=0.2)\n",
        "\n",
        "            condi_x = condi_x.view(-1, self.condi_featmap_dim * 4 * 4)\n",
        "            condi_x = self.fc_c(condi_x)\n",
        "            x = torch.cat((x, condi_x), 1)\n",
        "\n",
        "        # output layer\n",
        "        x = F.sigmoid(self.fc(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class CondiGAN_Generator(nn.Module):\n",
        "\n",
        "    def __init__(self, noise_dim=10, n_layer=3, condition=True,\n",
        "                 n_condition=100, use_gpu=False, featmap_dim=256, n_channel=1,\n",
        "                 condi_featmap_dim=256):\n",
        "        \"\"\"\n",
        "        Conditional Generator.\n",
        "        Architecture brought from DCGAN.\n",
        "        \"\"\"\n",
        "        super(CondiGAN_Generator, self).__init__()\n",
        "        self.n_layer = n_layer\n",
        "        self.condition = condition\n",
        "\n",
        "        # extra image information to be conditioned on\n",
        "        if self.condition:\n",
        "            self.condi_featmap_dim = condi_featmap_dim\n",
        "\n",
        "            convs_condi = []\n",
        "            BNs_condi = []\n",
        "            for layer in range(self.n_layer):\n",
        "                if layer == (self.n_layer - 1):\n",
        "                    n_conv_in = n_channel\n",
        "                else:\n",
        "                    n_conv_in = int(condi_featmap_dim / (2**(layer + 1)))\n",
        "                n_conv_out = int(condi_featmap_dim / (2**layer))\n",
        "\n",
        "                _conv = nn.Conv2d(n_conv_in, n_conv_out, kernel_size=5,\n",
        "                                  stride=2, padding=2)\n",
        "                if use_gpu:\n",
        "                    _conv = _conv.cuda()\n",
        "                convs_condi.append(_conv)\n",
        "\n",
        "                if layer != (self.n_layer - 1):\n",
        "                    _BN = nn.BatchNorm2d(n_conv_out)\n",
        "                    if use_gpu:\n",
        "                        _BN = _BN.cuda()\n",
        "                    BNs_condi.append(_BN)\n",
        "\n",
        "            self.fc_c = nn.Linear(condi_featmap_dim * 4 * 4, n_condition)\n",
        "\n",
        "        # calculate input dimension\n",
        "        n_input = noise_dim\n",
        "        if self.condition:\n",
        "            n_input += n_condition\n",
        "\n",
        "        # Generator\n",
        "        self.featmap_dim = featmap_dim\n",
        "        self.fc1 = nn.Linear(n_input, int(featmap_dim * 4 * 4))\n",
        "\n",
        "        convs = []\n",
        "        BNs = []\n",
        "        for layer in range(self.n_layer):\n",
        "            if layer == 0:\n",
        "                n_conv_out = n_channel\n",
        "            else:\n",
        "                n_conv_out = featmap_dim / (2 ** (self.n_layer - layer))\n",
        "            n_conv_in = featmap_dim / (2 ** (self.n_layer - layer - 1))\n",
        "\n",
        "            n_width = 5 if layer == (self.n_layer - 1) else 6\n",
        "            _conv = nn.ConvTranspose2d(n_conv_in, n_conv_out, n_width,\n",
        "                                       stride=2, padding=2)\n",
        "            if use_gpu:\n",
        "                _conv = _conv.cuda()\n",
        "            convs.append(_conv)\n",
        "\n",
        "            if layer != 0:\n",
        "                _BN = nn.BatchNorm2d(n_conv_out)\n",
        "                if use_gpu:\n",
        "                    _BN = _BN.cuda()\n",
        "                BNs.append(_BN)\n",
        "\n",
        "        # register layer modules\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.BNs = nn.ModuleList(BNs)\n",
        "        if self.condition:\n",
        "            self.convs_condi = nn.ModuleList(convs_condi)\n",
        "            self.BNs_condi = nn.ModuleList(BNs_condi)\n",
        "\n",
        "    def forward(self, x, condi_x=None):\n",
        "        \"\"\"\n",
        "        Concatenate CNN-processed extra information vector at the first layer\n",
        "        \"\"\"\n",
        "        # calculate and concatenate extra information\n",
        "        if self.condition:\n",
        "            for layer in range(self.n_layer):\n",
        "                _conv = self.convs_condi[self.n_layer - layer - 1]\n",
        "                if layer == 0:\n",
        "                    condi_x = F.leaky_relu(_conv(condi_x), negative_slope=0.2)\n",
        "                else:\n",
        "                    BN_layer = self.BNs_condi[self.n_layer - layer - 1]\n",
        "                    condi_x = F.leaky_relu(BN_layer(_conv(condi_x)),\n",
        "                                           negative_slope=0.2)\n",
        "\n",
        "            condi_x = condi_x.view(-1, self.condi_featmap_dim * 4 * 4)\n",
        "            condi_x = self.fc_c(condi_x)\n",
        "            x = torch.cat((x, condi_x), 1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = x.view(-1, self.featmap_dim, 4, 4)\n",
        "\n",
        "        for layer in range(self.n_layer):\n",
        "            conv_layer = self.convs[self.n_layer - layer - 1]\n",
        "            if layer == (self.n_layer - 1):\n",
        "                x = F.tanh(conv_layer(x))\n",
        "            else:\n",
        "                BN_layer = self.BNs[self.n_layer - layer - 2]\n",
        "                x = F.relu(BN_layer(conv_layer(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class LAPGAN(object):\n",
        "\n",
        "    def __init__(self, n_level, noise_dim=10, n_condition=100,\n",
        "                 D_featmap_dim=64, condi_D_featmap_dim=64,\n",
        "                 G_featmap_dim=256, condi_G_featmap_dim=64,\n",
        "                 use_gpu=False, n_channel=1):\n",
        "        \"\"\"\n",
        "        Initialize a group of discriminators and generators for LAPGAN\n",
        "        n_level: number of levels in the Laplacian Pyramid\n",
        "        noise_dim: dimension of random noise to feed into the last generator\n",
        "        D_featmap_dim: discriminator, (#feature maps) in the last layer of CNN\n",
        "        condi_D_featmap_dim: (#feature maps) of extra info CNN's last layer\n",
        "        G_featmap_dim: generator, (#feature maps) of deconvNN's first layer\n",
        "        condi_G_featmap_dim: (#feature maps) of extra info CNN's last layer\n",
        "        use_gpu: to use GPU computation or not\n",
        "        n_channel: number of channel for input images\n",
        "        \"\"\"\n",
        "        self.n_level = n_level\n",
        "        self.n_channel = n_channel\n",
        "        self.use_gpu = use_gpu\n",
        "        self.noise_dim = noise_dim\n",
        "        self.Dis_models = []\n",
        "        self.Gen_models = []\n",
        "\n",
        "        for level in range(n_level):\n",
        "            n_layer = n_level - level\n",
        "            if level == (n_level - 1):\n",
        "                condition = False\n",
        "            else:\n",
        "                condition = True\n",
        "\n",
        "            Dis_model = CondiGAN_Discriminator(n_layer, condition, n_condition,\n",
        "                                               use_gpu, D_featmap_dim,\n",
        "                                               n_channel, condi_D_featmap_dim)\n",
        "            Gen_model = CondiGAN_Generator(noise_dim, n_layer, condition,\n",
        "                                           n_condition, use_gpu, G_featmap_dim,\n",
        "                                           n_channel, condi_G_featmap_dim)\n",
        "\n",
        "            if use_gpu:\n",
        "                Dis_model = Dis_model.cuda()\n",
        "                Gen_model = Gen_model.cuda()\n",
        "\n",
        "            self.Dis_models.append(Dis_model)\n",
        "            self.Gen_models.append(Gen_model)\n",
        "\n",
        "    def generate(self, batchsize, get_level=None, generator=False):\n",
        "        \"\"\"Generate images from LAPGAN generators\"\"\"\n",
        "        self.outputs = []\n",
        "        self.generator_outputs = []\n",
        "        for level in range(self.n_level):\n",
        "            Gen_model = self.Gen_models[self.n_level - level - 1]\n",
        "\n",
        "            # generate noise\n",
        "            noise = Variable(gen_noise(batchsize, self.noise_dim))\n",
        "            if self.use_gpu:\n",
        "                noise = noise.cuda()\n",
        "\n",
        "            if level == 0:\n",
        "                # directly generate images\n",
        "                output_imgs = Gen_model.forward(noise)\n",
        "                if self.use_gpu:\n",
        "                    output_imgs = output_imgs.cpu()\n",
        "                output_imgs = output_imgs.data.numpy()\n",
        "                self.generator_outputs.append(output_imgs)\n",
        "            else:\n",
        "                # upsize\n",
        "                input_imgs = np.array([[cv2.pyrUp(output_imgs[i, j, :])\n",
        "                                      for j in range(self.n_channel)]\n",
        "                                      for i in range(batchsize)])\n",
        "                condi_imgs = Variable(torch.Tensor(input_imgs))\n",
        "                if self.use_gpu:\n",
        "                    condi_imgs = condi_imgs.cuda()\n",
        "\n",
        "                # generate images with extra information\n",
        "                residual_imgs = Gen_model.forward(noise, condi_imgs)\n",
        "                if self.use_gpu:\n",
        "                    residual_imgs = residual_imgs.cpu()\n",
        "                output_imgs = residual_imgs.data.numpy() + input_imgs\n",
        "                self.generator_outputs.append(residual_imgs.data.numpy())\n",
        "\n",
        "            self.outputs.append(output_imgs)\n",
        "\n",
        "        if get_level is None:\n",
        "            get_level = -1\n",
        "\n",
        "        if generator:\n",
        "            result_imgs = self.generator_outputs[get_level]\n",
        "        else:\n",
        "            result_imgs = self.outputs[get_level]\n",
        "\n",
        "        return result_imgs\n",
        "\n",
        "\n",
        "def gen_noise(n_instance, n_dim=2):\n",
        "    \"\"\"generate n-dim uniform random noise\"\"\"\n",
        "    return torch.Tensor(np.random.uniform(low=-1.0, high=1.0,\n",
        "                                          size=(n_instance, n_dim)))"
      ]
    }
  ]
}