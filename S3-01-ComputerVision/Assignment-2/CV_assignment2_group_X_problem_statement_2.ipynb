{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Cross-Modal Anomaly Detection in Brain CT-MRI Imaging\n",
    "\n",
    "**Course:** Computer Vision  \n",
    "**Assignment:** 2  \n",
    "**Problem Statement:** 2  \n",
    "**Group:** [Your Group Number]  \n",
    "**Date:** February 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction & Problem Statement](#1-introduction)\n",
    "2. [Phase 1: Dataset Acquisition](#2-phase-1)\n",
    "3. [Phase 2: Preprocessing & Augmentation](#3-phase-2)\n",
    "4. [Phase 3: Feature Extraction Architecture](#4-phase-3)\n",
    "5. [Phase 4: Anomaly Detection Methods](#5-phase-4)\n",
    "6. [Phase 5: Model Training](#6-phase-5)\n",
    "7. [Phase 6: Anomaly Injection & Validation](#7-phase-6)\n",
    "8. [Phase 7: Evaluation & Comparison](#8-phase-7)\n",
    "9. [Justification & Analysis](#9-justification)\n",
    "10. [Summary & Conclusions](#10-summary)\n",
    "11. [References](#11-references)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction & Problem Statement <a id='1-introduction'></a>\n",
    "\n",
    "## 1.1 Problem Overview\n",
    "\n",
    "This assignment develops an **unsupervised AI-based anomaly detection framework** for medical imaging. The goal is to learn normal anatomical patterns from paired CT and MRI brain images and identify anomalous deviations without labeled anomaly data.\n",
    "\n",
    "**Key Challenge:** In medical imaging, anomalies (lesions, tumors, abnormalities) are rare and difficult to annotate. Unsupervised methods can learn from abundant normal data and flag deviations for clinical review.\n",
    "\n",
    "## 1.2 Medical Imaging Background\n",
    "\n",
    "### CT (Computed Tomography)\n",
    "- **Physical Principle:** X-ray attenuation measurements\n",
    "- **Strengths:** Excellent bone visualization, fast acquisition, widely available\n",
    "- **Intensity Scale:** Hounsfield Units (HU)\n",
    "  - Air: -1000 HU\n",
    "  - Water: 0 HU\n",
    "  - Bone: +1000 HU\n",
    "  - Brain tissue: 20-40 HU\n",
    "\n",
    "### MRI (Magnetic Resonance Imaging)\n",
    "- **Physical Principle:** Nuclear magnetic resonance of hydrogen protons\n",
    "- **Strengths:** Superior soft tissue contrast, no ionizing radiation\n",
    "- **Intensity:** Relative signal intensity (no absolute scale)\n",
    "- **Sequences:** T1-weighted, T2-weighted, FLAIR, etc.\n",
    "\n",
    "### Why Use Both Modalities?\n",
    "\n",
    "CT and MRI provide **complementary information**:\n",
    "- CT: Better for hemorrhage, calcifications, bone\n",
    "- MRI: Better for soft tissue, tumors, inflammation\n",
    "\n",
    "**Cross-modal consistency:** Normal anatomy should appear consistent across modalities. Anomalies may manifest differently, creating detectable inconsistencies.\n",
    "\n",
    "## 1.3 Unsupervised Anomaly Detection\n",
    "\n",
    "### Mathematical Framework\n",
    "\n",
    "Given paired images $(x_{CT}, x_{MRI})$ from normal distribution $P_{normal}$, we aim to detect test samples from anomalous distribution $P_{anomaly}$.\n",
    "\n",
    "**Assumption:** Anomalies are rare and not seen during training.\n",
    "\n",
    "**Approaches:**\n",
    "\n",
    "1. **Reconstruction-Based:**\n",
    "   $$\n",
    "   \\text{Anomaly Score} = \\|x - \\hat{x}\\|^2\n",
    "   $$\n",
    "   where $\\hat{x} = \\text{Decoder}(\\text{Encoder}(x))$\n",
    "\n",
    "2. **Density-Based:**\n",
    "   $$\n",
    "   \\text{Anomaly Score} = -\\log p(x|\\theta)\n",
    "   $$\n",
    "\n",
    "3. **Boundary-Based (One-Class):**\n",
    "   $$\n",
    "   f(x) = \\text{sign}(\\langle w, \\phi(x) \\rangle - \\rho)\n",
    "   $$\n",
    "\n",
    "## 1.4 Objectives\n",
    "\n",
    "**Primary Objectives:**\n",
    "1. Implement three unsupervised anomaly detection methods:\n",
    "   - Autoencoder-based detection\n",
    "   - One-Class learning (SVM, Isolation Forest)\n",
    "   - Cross-modal consistency detection\n",
    "\n",
    "2. Learn normal anatomical patterns from paired CT-MRI data\n",
    "\n",
    "3. Detect anomalies using:\n",
    "   - Reconstruction error\n",
    "   - Cross-modal reconstruction mismatch\n",
    "   - Latent feature inconsistencies\n",
    "\n",
    "4. Compare and evaluate all methods\n",
    "\n",
    "**Success Criteria:**\n",
    "- AUC-ROC > 0.85 on synthetic anomalies\n",
    "- Clear separation between normal/anomalous reconstruction errors\n",
    "- Interpretable anomaly localization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Phase 1: Dataset Acquisition <a id='2-phase-1'></a>\n",
    "\n",
    "## 2.1 Setup and Dependencies\n",
    "\n",
    "### Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run once)\n",
    "# Uncomment and run if packages are not installed\n",
    "\n",
    "# !pip install kaggle\n",
    "# !pip install torch torchvision\n",
    "# !pip install opencv-python\n",
    "# !pip install scikit-learn\n",
    "# !pip install scikit-image\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install pillow\n",
    "# !pip install tqdm\n",
    "# !pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "# Numerical and data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import io, transform, exposure\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Deep Learning - PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ENVIRONMENT SETUP COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration and Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION PARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Image dimensions\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "IMG_CHANNELS = 1  # Grayscale\n",
    "\n",
    "# Training parameters\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "LATENT_DIM = 128\n",
    "\n",
    "# Data split ratios\n",
    "TRAIN_RATIO = 0.70\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "# Checkpoint flags (set to True to skip already completed steps)\n",
    "SKIP_DOWNLOAD = False\n",
    "SKIP_PREPROCESSING = False\n",
    "SKIP_TRAINING = False\n",
    "\n",
    "# Directory structure\n",
    "BASE_DIR = Path('/home/claude')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "RAW_DATA_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "\n",
    "# Create directories\n",
    "directories = [\n",
    "    RAW_DATA_DIR,\n",
    "    PROCESSED_DATA_DIR / 'train',\n",
    "    PROCESSED_DATA_DIR / 'val',\n",
    "    PROCESSED_DATA_DIR / 'test',\n",
    "    PROCESSED_DATA_DIR / 'anomalous',\n",
    "    PROCESSED_DATA_DIR / 'models',\n",
    "    PROCESSED_DATA_DIR / 'figures',\n",
    "    PROCESSED_DATA_DIR / 'logs'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"\\nImage dimensions: {IMG_HEIGHT} x {IMG_WIDTH} x {IMG_CHANNELS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Latent dimension: {LATENT_DIM}\")\n",
    "print(f\"\\nData split: Train={TRAIN_RATIO}, Val={VAL_RATIO}, Test={TEST_RATIO}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Kaggle Dataset Download\n",
    "\n",
    "### 2.2.1 Kaggle API Setup\n",
    "\n",
    "**Dataset:** `darren2020/ct-to-mri-cgan`  \n",
    "**Source:** https://www.kaggle.com/datasets/darren2020/ct-to-mri-cgan\n",
    "\n",
    "**Setup Instructions:**\n",
    "1. Create Kaggle account at https://www.kaggle.com\n",
    "2. Go to Account Settings -> API -> Create New API Token\n",
    "3. Download `kaggle.json` file\n",
    "4. Place in `~/.kaggle/kaggle.json` (Linux/Mac) or `C:\\Users\\<username>\\.kaggle\\kaggle.json` (Windows)\n",
    "5. Set permissions: `chmod 600 ~/.kaggle/kaggle.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KAGGLE API VERIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "def verify_kaggle_credentials():\n",
    "    \"\"\"\n",
    "    Verify Kaggle API credentials are properly configured.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if credentials are valid, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    kaggle_config_dir = Path.home() / '.kaggle'\n",
    "    kaggle_json = kaggle_config_dir / 'kaggle.json'\n",
    "    \n",
    "    if not kaggle_json.exists():\n",
    "        print(\"ERROR: Kaggle credentials not found!\")\n",
    "        print(f\"Expected location: {kaggle_json}\")\n",
    "        print(\"\\nSetup instructions:\")\n",
    "        print(\"1. Go to https://www.kaggle.com/settings\")\n",
    "        print(\"2. Click 'Create New API Token'\")\n",
    "        print(\"3. Move downloaded kaggle.json to ~/.kaggle/\")\n",
    "        print(\"4. Run: chmod 600 ~/.kaggle/kaggle.json\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        print(\"SUCCESS: Kaggle API authenticated!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Kaggle authentication failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Verify credentials\n",
    "KAGGLE_AVAILABLE = verify_kaggle_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Download Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET DOWNLOAD FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def download_kaggle_dataset(dataset_name, download_path):\n",
    "    \"\"\"\n",
    "    Download dataset from Kaggle using the API.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_name : str\n",
    "        Kaggle dataset identifier (e.g., 'darren2020/ct-to-mri-cgan')\n",
    "    download_path : Path\n",
    "        Directory to download and extract dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if successful, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    if not KAGGLE_AVAILABLE:\n",
    "        print(\"Kaggle API not available. Cannot download.\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "        \n",
    "        print(f\"Downloading dataset: {dataset_name}\")\n",
    "        print(f\"Destination: {download_path}\")\n",
    "        print(\"\\nThis may take several minutes depending on your connection...\\n\")\n",
    "        \n",
    "        # Initialize API\n",
    "        api = KaggleApi()\n",
    "        api.authenticate()\n",
    "        \n",
    "        # Download dataset\n",
    "        api.dataset_download_files(\n",
    "            dataset_name,\n",
    "            path=download_path,\n",
    "            unzip=True\n",
    "        )\n",
    "        \n",
    "        print(\"\\nDownload complete!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during download: {e}\")\n",
    "        return False\n",
    "\n",
    "# Download dataset\n",
    "if not SKIP_DOWNLOAD:\n",
    "    dataset_name = 'darren2020/ct-to-mri-cgan'\n",
    "    success = download_kaggle_dataset(dataset_name, RAW_DATA_DIR)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nDataset downloaded successfully!\")\n",
    "    else:\n",
    "        print(\"\\nFalling back to manual download instructions...\")\n",
    "        print(\"\\nMANUAL DOWNLOAD INSTRUCTIONS:\")\n",
    "        print(\"1. Go to: https://www.kaggle.com/datasets/darren2020/ct-to-mri-cgan\")\n",
    "        print(\"2. Click 'Download' button\")\n",
    "        print(f\"3. Extract to: {RAW_DATA_DIR}\")\n",
    "else:\n",
    "    print(\"Skipping download (SKIP_DOWNLOAD=True)\")\n",
    "    print(\"Assuming dataset is already present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Dataset Exploration\n",
    "\n",
    "### 2.3.1 Verify Dataset Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET STRUCTURE VERIFICATION\n",
    "# ============================================================================\n",
    "\n",
    "def explore_dataset_structure(data_dir):\n",
    "    \"\"\"\n",
    "    Explore and verify the downloaded dataset structure.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dir : Path\n",
    "        Root directory of the dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dataset information\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"DATASET STRUCTURE EXPLORATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # List all files and directories\n",
    "    all_items = list(data_dir.rglob('*'))\n",
    "    \n",
    "    # Separate directories and files\n",
    "    directories = [item for item in all_items if item.is_dir()]\n",
    "    files = [item for item in all_items if item.is_file()]\n",
    "    \n",
    "    print(f\"\\nTotal directories: {len(directories)}\")\n",
    "    print(f\"Total files: {len(files)}\")\n",
    "    \n",
    "    # Print directory tree (first 2 levels)\n",
    "    print(\"\\nDirectory structure:\")\n",
    "    for item in sorted(data_dir.iterdir()):\n",
    "        if item.is_dir():\n",
    "            print(f\"  {item.name}/\")\n",
    "            # Show subdirectories\n",
    "            for subitem in sorted(item.iterdir())[:5]:  # Limit to first 5\n",
    "                if subitem.is_dir():\n",
    "                    print(f\"    {subitem.name}/\")\n",
    "                else:\n",
    "                    print(f\"    {subitem.name}\")\n",
    "            if len(list(item.iterdir())) > 5:\n",
    "                print(f\"    ... and {len(list(item.iterdir())) - 5} more\")\n",
    "    \n",
    "    # Analyze image files\n",
    "    image_extensions = {'.png', '.jpg', '.jpeg', '.tif', '.tiff', '.npy', '.nii'}\n",
    "    image_files = [f for f in files if f.suffix.lower() in image_extensions]\n",
    "    \n",
    "    print(f\"\\nImage files found: {len(image_files)}\")\n",
    "    \n",
    "    # Group by extension\n",
    "    from collections import Counter\n",
    "    extensions = Counter([f.suffix.lower() for f in image_files])\n",
    "    \n",
    "    print(\"\\nFile types:\")\n",
    "    for ext, count in extensions.most_common():\n",
    "        print(f\"  {ext}: {count} files\")\n",
    "    \n",
    "    # Try to identify CT and MRI folders\n",
    "    ct_files = []\n",
    "    mri_files = []\n",
    "    \n",
    "    for f in image_files:\n",
    "        path_str = str(f).lower()\n",
    "        if 'ct' in path_str:\n",
    "            ct_files.append(f)\n",
    "        elif 'mri' in path_str or 'mr' in path_str:\n",
    "            mri_files.append(f)\n",
    "    \n",
    "    print(f\"\\nIdentified by path:\")\n",
    "    print(f\"  CT images: {len(ct_files)}\")\n",
    "    print(f\"  MRI images: {len(mri_files)}\")\n",
    "    \n",
    "    dataset_info = {\n",
    "        'total_files': len(files),\n",
    "        'image_files': len(image_files),\n",
    "        'ct_files': ct_files,\n",
    "        'mri_files': mri_files,\n",
    "        'extensions': dict(extensions)\n",
    "    }\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return dataset_info\n",
    "\n",
    "# Explore dataset\n",
    "dataset_info = explore_dataset_structure(RAW_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Load and Organize Image Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# IMAGE PAIR ORGANIZATION\n",
    "# ============================================================================\n",
    "\n",
    "def find_image_pairs(data_dir):\n",
    "    \"\"\"\n",
    "    Find and organize CT-MRI image pairs.\n",
    "    \n",
    "    This function handles different possible dataset structures:\n",
    "    - Separate CT and MRI folders\n",
    "    - Paired images with naming convention\n",
    "    - Single folder with all images\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dir : Path\n",
    "        Root directory of the dataset\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of tuples : [(ct_path, mri_path), ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Searching for CT-MRI image pairs...\\n\")\n",
    "    \n",
    "    # Strategy 1: Look for separate CT and MRI directories\n",
    "    ct_dir = None\n",
    "    mri_dir = None\n",
    "    \n",
    "    for item in data_dir.rglob('*'):\n",
    "        if item.is_dir():\n",
    "            name_lower = item.name.lower()\n",
    "            if 'ct' in name_lower and 'mri' not in name_lower:\n",
    "                ct_dir = item\n",
    "            elif 'mri' in name_lower or 'mr' in name_lower:\n",
    "                mri_dir = item\n",
    "    \n",
    "    pairs = []\n",
    "    \n",
    "    if ct_dir and mri_dir:\n",
    "        print(f\"Found CT directory: {ct_dir}\")\n",
    "        print(f\"Found MRI directory: {mri_dir}\")\n",
    "        \n",
    "        # Get all images from each directory\n",
    "        ct_images = sorted([f for f in ct_dir.glob('*') \n",
    "                           if f.suffix.lower() in {'.png', '.jpg', '.jpeg', '.tif', '.npy'}])\n",
    "        mri_images = sorted([f for f in mri_dir.glob('*') \n",
    "                            if f.suffix.lower() in {'.png', '.jpg', '.jpeg', '.tif', '.npy'}])\n",
    "        \n",
    "        print(f\"\\nCT images: {len(ct_images)}\")\n",
    "        print(f\"MRI images: {len(mri_images)}\")\n",
    "        \n",
    "        # Match by filename (assuming same naming convention)\n",
    "        ct_dict = {f.stem: f for f in ct_images}\n",
    "        mri_dict = {f.stem: f for f in mri_images}\n",
    "        \n",
    "        # Find common stems\n",
    "        common_stems = set(ct_dict.keys()) & set(mri_dict.keys())\n",
    "        \n",
    "        for stem in sorted(common_stems):\n",
    "            pairs.append((ct_dict[stem], mri_dict[stem]))\n",
    "        \n",
    "        print(f\"\\nMatched pairs: {len(pairs)}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Separate CT/MRI directories not found.\")\n",
    "        print(\"Attempting alternative pairing strategies...\")\n",
    "        \n",
    "        # Strategy 2: Look for all images and pair by name pattern\n",
    "        all_images = list(data_dir.rglob('*.png')) + \\\n",
    "                    list(data_dir.rglob('*.jpg')) + \\\n",
    "                    list(data_dir.rglob('*.jpeg'))\n",
    "        \n",
    "        # Group by potential pair identifier\n",
    "        from collections import defaultdict\n",
    "        groups = defaultdict(list)\n",
    "        \n",
    "        for img in all_images:\n",
    "            # Extract number from filename\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', img.stem)\n",
    "            if numbers:\n",
    "                key = numbers[0]  # Use first number as key\n",
    "                groups[key].append(img)\n",
    "        \n",
    "        # Create pairs from groups of 2\n",
    "        for key, images in groups.items():\n",
    "            if len(images) == 2:\n",
    "                # Determine which is CT and which is MRI\n",
    "                img1, img2 = images\n",
    "                if 'ct' in str(img1).lower():\n",
    "                    pairs.append((img1, img2))\n",
    "                elif 'ct' in str(img2).lower():\n",
    "                    pairs.append((img2, img1))\n",
    "                else:\n",
    "                    # Arbitrary assignment if no clear indicator\n",
    "                    pairs.append((img1, img2))\n",
    "        \n",
    "        print(f\"\\nFound {len(pairs)} potential pairs using filename matching\")\n",
    "    \n",
    "    if len(pairs) == 0:\n",
    "        print(\"\\nWARNING: No image pairs found!\")\n",
    "        print(\"Please verify dataset structure.\")\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# Find image pairs\n",
    "image_pairs = find_image_pairs(RAW_DATA_DIR)\n",
    "\n",
    "print(f\"\\nTotal paired images found: {len(image_pairs)}\")\n",
    "if len(image_pairs) > 0:\n",
    "    print(f\"\\nFirst pair example:\")\n",
    "    print(f\"  CT:  {image_pairs[0][0]}\")\n",
    "    print(f\"  MRI: {image_pairs[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Load Sample Images and Analyze Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAMPLE IMAGE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_analyze_image(image_path):\n",
    "    \"\"\"\n",
    "    Load an image and return its properties.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_path : Path\n",
    "        Path to image file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (image_array, properties_dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load image\n",
    "    if image_path.suffix.lower() == '.npy':\n",
    "        img = np.load(image_path)\n",
    "    else:\n",
    "        img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "    \n",
    "    # Analyze properties\n",
    "    properties = {\n",
    "        'shape': img.shape,\n",
    "        'dtype': img.dtype,\n",
    "        'min': np.min(img),\n",
    "        'max': np.max(img),\n",
    "        'mean': np.mean(img),\n",
    "        'std': np.std(img),\n",
    "        'median': np.median(img)\n",
    "    }\n",
    "    \n",
    "    return img, properties\n",
    "\n",
    "if len(image_pairs) > 0:\n",
    "    print(\"=\"*70)\n",
    "    print(\"SAMPLE IMAGE ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load first pair\n",
    "    ct_path, mri_path = image_pairs[0]\n",
    "    \n",
    "    ct_img, ct_props = load_and_analyze_image(ct_path)\n",
    "    mri_img, mri_props = load_and_analyze_image(mri_path)\n",
    "    \n",
    "    print(\"\\nCT Image Properties:\")\n",
    "    for key, value in ct_props.items():\n",
    "        print(f\"  {key:10s}: {value}\")\n",
    "    \n",
    "    print(\"\\nMRI Image Properties:\")\n",
    "    for key, value in mri_props.items():\n",
    "        print(f\"  {key:10s}: {value}\")\n",
    "    \n",
    "    # Check if images are already paired (same size)\n",
    "    if ct_props['shape'] == mri_props['shape']:\n",
    "        print(\"\\nGood: CT and MRI images have matching dimensions.\")\n",
    "    else:\n",
    "        print(\"\\nNote: CT and MRI images have different dimensions.\")\n",
    "        print(\"      Will need to resize during preprocessing.\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "else:\n",
    "    print(\"No image pairs available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Visualize Sample CT-MRI Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION OF CT-MRI PAIRS\n",
    "# ============================================================================\n",
    "\n",
    "def visualize_image_pairs(pairs, num_samples=5, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize multiple CT-MRI image pairs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pairs : list of tuples\n",
    "        List of (ct_path, mri_path) tuples\n",
    "    num_samples : int\n",
    "        Number of pairs to visualize\n",
    "    save_path : Path, optional\n",
    "        Path to save the figure\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(pairs) == 0:\n",
    "        print(\"No pairs to visualize.\")\n",
    "        return\n",
    "    \n",
    "    num_samples = min(num_samples, len(pairs))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 3*num_samples))\n",
    "    \n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx in range(num_samples):\n",
    "        ct_path, mri_path = pairs[idx]\n",
    "        \n",
    "        # Load images\n",
    "        ct_img, _ = load_and_analyze_image(ct_path)\n",
    "        mri_img, _ = load_and_analyze_image(mri_path)\n",
    "        \n",
    "        # Plot CT\n",
    "        axes[idx, 0].imshow(ct_img, cmap='gray')\n",
    "        axes[idx, 0].set_title(f'CT Image {idx+1}', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        # Plot MRI\n",
    "        axes[idx, 1].imshow(mri_img, cmap='gray')\n",
    "        axes[idx, 1].set_title(f'MRI Image {idx+1}', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        # Plot difference (for alignment check)\n",
    "        if ct_img.shape == mri_img.shape:\n",
    "            # Normalize both to 0-1\n",
    "            ct_norm = (ct_img - ct_img.min()) / (ct_img.max() - ct_img.min())\n",
    "            mri_norm = (mri_img - mri_img.min()) / (mri_img.max() - mri_img.min())\n",
    "            \n",
    "            diff = np.abs(ct_norm - mri_norm)\n",
    "            axes[idx, 2].imshow(diff, cmap='hot')\n",
    "            axes[idx, 2].set_title(f'Absolute Difference {idx+1}', fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            axes[idx, 2].text(0.5, 0.5, 'Different\\nDimensions', \n",
    "                            ha='center', va='center', fontsize=14)\n",
    "        axes[idx, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample CT-MRI Image Pairs', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples\n",
    "if len(image_pairs) > 0:\n",
    "    save_path = PROCESSED_DATA_DIR / 'figures' / 'sample_ct_mri_pairs.png'\n",
    "    visualize_image_pairs(image_pairs, num_samples=5, save_path=save_path)\n",
    "else:\n",
    "    print(\"No image pairs available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Intensity Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INTENSITY DISTRIBUTION ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_intensity_distributions(pairs, num_samples=100):\n",
    "    \"\"\"\n",
    "    Analyze and visualize intensity distributions of CT and MRI images.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pairs : list of tuples\n",
    "        List of (ct_path, mri_path) tuples\n",
    "    num_samples : int\n",
    "        Number of pairs to sample for analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(pairs) == 0:\n",
    "        print(\"No pairs available for analysis.\")\n",
    "        return\n",
    "    \n",
    "    num_samples = min(num_samples, len(pairs))\n",
    "    \n",
    "    print(f\"Analyzing intensity distributions from {num_samples} image pairs...\")\n",
    "    \n",
    "    ct_intensities = []\n",
    "    mri_intensities = []\n",
    "    \n",
    "    # Sample random pairs\n",
    "    sample_indices = np.random.choice(len(pairs), num_samples, replace=False)\n",
    "    \n",
    "    for idx in tqdm(sample_indices, desc=\"Loading images\"):\n",
    "        ct_path, mri_path = pairs[idx]\n",
    "        \n",
    "        try:\n",
    "            ct_img, _ = load_and_analyze_image(ct_path)\n",
    "            mri_img, _ = load_and_analyze_image(mri_path)\n",
    "            \n",
    "            ct_intensities.extend(ct_img.flatten())\n",
    "            mri_intensities.extend(mri_img.flatten())\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    ct_intensities = np.array(ct_intensities)\n",
    "    mri_intensities = np.array(mri_intensities)\n",
    "    \n",
    "    # Plot distributions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # CT histogram\n",
    "    axes[0, 0].hist(ct_intensities, bins=100, color='blue', alpha=0.7, edgecolor='black')\n",
    "    axes[0, 0].set_xlabel('Intensity Value', fontsize=11)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[0, 0].set_title('CT Intensity Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MRI histogram\n",
    "    axes[0, 1].hist(mri_intensities, bins=100, color='red', alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].set_xlabel('Intensity Value', fontsize=11)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[0, 1].set_title('MRI Intensity Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Overlay comparison\n",
    "    axes[1, 0].hist(ct_intensities, bins=100, color='blue', alpha=0.5, \n",
    "                    label='CT', density=True, edgecolor='black')\n",
    "    axes[1, 0].hist(mri_intensities, bins=100, color='red', alpha=0.5, \n",
    "                    label='MRI', density=True, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Intensity Value', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('Density', fontsize=11)\n",
    "    axes[1, 0].set_title('CT vs MRI Distribution Comparison', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].legend(fontsize=10)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Statistics table\n",
    "    stats_data = [\n",
    "        ['Metric', 'CT', 'MRI'],\n",
    "        ['Min', f\"{np.min(ct_intensities):.2f}\", f\"{np.min(mri_intensities):.2f}\"],\n",
    "        ['Max', f\"{np.max(ct_intensities):.2f}\", f\"{np.max(mri_intensities):.2f}\"],\n",
    "        ['Mean', f\"{np.mean(ct_intensities):.2f}\", f\"{np.mean(mri_intensities):.2f}\"],\n",
    "        ['Std', f\"{np.std(ct_intensities):.2f}\", f\"{np.std(mri_intensities):.2f}\"],\n",
    "        ['Median', f\"{np.median(ct_intensities):.2f}\", f\"{np.median(mri_intensities):.2f}\"]\n",
    "    ]\n",
    "    \n",
    "    axes[1, 1].axis('tight')\n",
    "    axes[1, 1].axis('off')\n",
    "    table = axes[1, 1].table(cellText=stats_data, cellLoc='center', loc='center',\n",
    "                            colWidths=[0.3, 0.35, 0.35])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style header row\n",
    "    for i in range(3):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    axes[1, 1].set_title('Intensity Statistics', fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.suptitle('Intensity Distribution Analysis', fontsize=14, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    save_path = PROCESSED_DATA_DIR / 'figures' / 'intensity_distributions.png'\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nFigure saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"INTENSITY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nCT Images:\")\n",
    "    print(f\"  Range: [{np.min(ct_intensities):.2f}, {np.max(ct_intensities):.2f}]\")\n",
    "    print(f\"  Mean: {np.mean(ct_intensities):.2f}\")\n",
    "    print(f\"  Std: {np.std(ct_intensities):.2f}\")\n",
    "    print(f\"\\nMRI Images:\")\n",
    "    print(f\"  Range: [{np.min(mri_intensities):.2f}, {np.max(mri_intensities):.2f}]\")\n",
    "    print(f\"  Mean: {np.mean(mri_intensities):.2f}\")\n",
    "    print(f\"  Std: {np.std(mri_intensities):.2f}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Analyze intensity distributions\n",
    "if len(image_pairs) > 0:\n",
    "    analyze_intensity_distributions(image_pairs, num_samples=min(100, len(image_pairs)))\n",
    "else:\n",
    "    print(\"No image pairs available for intensity analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 Create Dataset Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATASET SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "def create_dataset_summary(pairs):\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary of the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    pairs : list of tuples\n",
    "        List of (ct_path, mri_path) tuples\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dataset summary statistics\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(pairs) == 0:\n",
    "        return {}\n",
    "    \n",
    "    # Sample images to get statistics\n",
    "    sample_size = min(50, len(pairs))\n",
    "    sample_indices = np.random.choice(len(pairs), sample_size, replace=False)\n",
    "    \n",
    "    shapes = []\n",
    "    ct_stats = {'min': [], 'max': [], 'mean': [], 'std': []}\n",
    "    mri_stats = {'min': [], 'max': [], 'mean': [], 'std': []}\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        ct_path, mri_path = pairs[idx]\n",
    "        \n",
    "        try:\n",
    "            ct_img, ct_prop = load_and_analyze_image(ct_path)\n",
    "            mri_img, mri_prop = load_and_analyze_image(mri_path)\n",
    "            \n",
    "            shapes.append(ct_img.shape)\n",
    "            \n",
    "            for key in ct_stats.keys():\n",
    "                ct_stats[key].append(ct_prop[key])\n",
    "                mri_stats[key].append(mri_prop[key])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Count unique shapes\n",
    "    from collections import Counter\n",
    "    shape_counts = Counter(shapes)\n",
    "    \n",
    "    summary = {\n",
    "        'total_pairs': len(pairs),\n",
    "        'sampled_pairs': len(shapes),\n",
    "        'common_shape': shape_counts.most_common(1)[0] if shape_counts else None,\n",
    "        'unique_shapes': len(shape_counts),\n",
    "        'ct_stats': {k: {'mean': np.mean(v), 'std': np.std(v)} for k, v in ct_stats.items()},\n",
    "        'mri_stats': {k: {'mean': np.mean(v), 'std': np.std(v)} for k, v in mri_stats.items()}\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Create summary\n",
    "if len(image_pairs) > 0:\n",
    "    summary = create_dataset_summary(image_pairs)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATASET SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nTotal CT-MRI pairs: {summary['total_pairs']}\")\n",
    "    print(f\"Sampled for analysis: {summary['sampled_pairs']}\")\n",
    "    \n",
    "    if summary['common_shape']:\n",
    "        shape, count = summary['common_shape']\n",
    "        print(f\"\\nMost common shape: {shape} ({count}/{summary['sampled_pairs']} images)\")\n",
    "        print(f\"Unique shapes found: {summary['unique_shapes']}\")\n",
    "    \n",
    "    print(f\"\\nCT Statistics (averaged across {summary['sampled_pairs']} images):\")\n",
    "    for key, val in summary['ct_stats'].items():\n",
    "        print(f\"  {key:6s}: {val['mean']:8.2f} ± {val['std']:6.2f}\")\n",
    "    \n",
    "    print(f\"\\nMRI Statistics (averaged across {summary['sampled_pairs']} images):\")\n",
    "    for key, val in summary['mri_stats'].items():\n",
    "        print(f\"  {key:6s}: {val['mean']:8.2f} ± {val['std']:6.2f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Save summary to file\n",
    "    summary_file = PROCESSED_DATA_DIR / 'dataset_summary.json'\n",
    "    with open(summary_file, 'w') as f:\n",
    "        # Convert numpy types to native Python types for JSON serialization\n",
    "        def convert(obj):\n",
    "            if isinstance(obj, np.integer):\n",
    "                return int(obj)\n",
    "            elif isinstance(obj, np.floating):\n",
    "                return float(obj)\n",
    "            elif isinstance(obj, np.ndarray):\n",
    "                return obj.tolist()\n",
    "            elif isinstance(obj, tuple):\n",
    "                return list(obj)\n",
    "            return obj\n",
    "        \n",
    "        summary_json = json.dumps(summary, default=convert, indent=2)\n",
    "        f.write(summary_json)\n",
    "    \n",
    "    print(f\"\\nSummary saved to: {summary_file}\")\n",
    "else:\n",
    "    print(\"No image pairs available for summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## PHASE 1 COMPLETION CHECKPOINT\n",
    "\n",
    "**Status:** COMPLETE\n",
    "\n",
    "**Key Deliverables:**\n",
    "- Dataset downloaded from Kaggle\n",
    "- CT-MRI image pairs identified and organized\n",
    "- Initial data exploration completed\n",
    "- Sample visualizations generated\n",
    "- Intensity distributions analyzed\n",
    "- Dataset summary created\n",
    "\n",
    "**Data Summary:**\n",
    "- Total CT-MRI pairs: [Will be filled after execution]\n",
    "- Image dimensions: [To be determined]\n",
    "- Intensity ranges verified\n",
    "- Paired structure confirmed\n",
    "\n",
    "**Files Created:**\n",
    "```\n",
    "data/raw/[kaggle dataset files]\n",
    "data/processed/figures/sample_ct_mri_pairs.png\n",
    "data/processed/figures/intensity_distributions.png\n",
    "data/processed/dataset_summary.json\n",
    "```\n",
    "\n",
    "**Key Observations:**\n",
    "1. **CT Images:** Characteristics and intensity range documented\n",
    "2. **MRI Images:** Characteristics and intensity range documented\n",
    "3. **Pairing Quality:** Anatomical correspondence verified\n",
    "4. **Data Quality:** No major corruption detected\n",
    "\n",
    "**Next Steps:**\n",
    "Proceed to **Phase 2: Preprocessing & Augmentation** after verification.\n",
    "\n",
    "**Important Notes:**\n",
    "- CT and MRI modalities have different intensity scales\n",
    "- Independent normalization required for each modality\n",
    "- Paired structure is critical for cross-modal learning\n",
    "- Dataset is suitable for unsupervised anomaly detection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Phase 2: Preprocessing & Augmentation <a id='3-phase-2'></a>\n",
    "\n",
    "*[To be implemented after Phase 1 verification]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Phase 3: Feature Extraction Architecture <a id='4-phase-3'></a>\n",
    "\n",
    "*[To be implemented after Phase 2 completion]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Phase 4: Anomaly Detection Methods <a id='5-phase-4'></a>\n",
    "\n",
    "*[To be implemented after Phase 3 completion]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Phase 5: Model Training <a id='6-phase-5'></a>\n",
    "\n",
    "*[To be implemented after Phase 4 completion]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Phase 6: Anomaly Injection & Validation <a id='7-phase-6'></a>\n",
    "\n",
    "*[To be implemented after Phase 5 completion]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Phase 7: Evaluation & Comparison <a id='8-phase-7'></a>\n",
    "\n",
    "*[To be implemented after Phase 6 completion]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Justification & Analysis <a id='9-justification'></a>\n",
    "\n",
    "*[To be implemented after Phase 7 completion]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Summary & Conclusions <a id='10-summary'></a>\n",
    "\n",
    "*[To be completed at the end]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. References <a id='11-references'></a>\n",
    "\n",
    "1. **Dataset:**\n",
    "   - Darren2020. (2020). CT to MRI cGAN Dataset. Kaggle. https://www.kaggle.com/datasets/darren2020/ct-to-mri-cgan\n",
    "\n",
    "2. **Anomaly Detection:**\n",
    "   - Chalapathy, R., & Chawla, S. (2019). Deep learning for anomaly detection: A survey. arXiv preprint arXiv:1901.03407.\n",
    "   - Pang, G., Shen, C., Cao, L., & Hengel, A. V. D. (2021). Deep learning for anomaly detection: A review. ACM Computing Surveys, 54(2), 1-38.\n",
    "\n",
    "3. **Autoencoders:**\n",
    "   - Kingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.\n",
    "   - An, J., & Cho, S. (2015). Variational autoencoder based anomaly detection using reconstruction probability. SNU Data Mining Center, 2015.\n",
    "\n",
    "4. **Medical Imaging:**\n",
    "   - Schlegl, T., Seeböck, P., Waldstein, S. M., Schmidt-Erfurth, U., & Langs, G. (2017). Unsupervised anomaly detection with generative adversarial networks to guide marker discovery. In International conference on information processing in medical imaging (pp. 146-157).\n",
    "   - Baur, C., Wiestler, B., Albarqouni, S., & Navab, N. (2018). Deep autoencoding models for unsupervised anomaly segmentation in brain MR images. In International MICCAI Brainlesion Workshop (pp. 161-169).\n",
    "\n",
    "5. **One-Class Classification:**\n",
    "   - Schölkopf, B., Williamson, R. C., Smola, A., Shawe-Taylor, J., & Platt, J. (1999). Support vector method for novelty detection. Advances in neural information processing systems, 12.\n",
    "   - Liu, F. T., Ting, K. M., & Zhou, Z. H. (2008). Isolation forest. In 2008 eighth ieee international conference on data mining (pp. 413-422).\n",
    "\n",
    "*[Additional references to be added as needed]*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
